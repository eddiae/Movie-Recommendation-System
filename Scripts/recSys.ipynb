{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System using MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import heapq\n",
    "import decimal\n",
    "import operator\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import rpy2.robjects as ro\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "from networkx.algorithms import community\n",
    "from rpy2.robjects.packages import importr\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import datasets, linear_model,tree\n",
    "from surprise.model_selection import cross_validate, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from surprise import Reader, Dataset, SVD, evaluate, accuracy\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin loading all files - u.user, u.item, u.data into workable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user profile\n",
    "userCols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=userCols)\n",
    "#users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie profile with genres (full)\n",
    "with open('./ml-100k/u.item') as content:\n",
    "    mCols = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "    genres = ['unknown', 'action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', \n",
    "          'film-noir',  'horror', 'musical', 'mystery', 'romance', 'sci-fi', 'thriller', 'war', 'western']\n",
    "    mColsG = mCols + genres\n",
    "    moviesG = pd.DataFrame(columns=mColsG)\n",
    "    i = 0\n",
    "    for x in content:\n",
    "        x = x.split(\"|\")\n",
    "        x[-1] = x[-1][:-1]\n",
    "        if x[1][-1] == ' ':\n",
    "            x[1] = x[1][:-1]\n",
    "        moviesG.loc[i] = [word if word!='' else \"empty\" for word in x]\n",
    "        i = i + 1\n",
    "moviesG['movie_id'] = moviesG['movie_id'].astype('int64')\n",
    "moviesG[genres] = moviesG[genres].astype('int64')\n",
    "#moviesG.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove video_release_date since column values are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'video_release_date' in moviesG.columns:\n",
    "    moviesG = moviesG.drop('video_release_date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies profile with encoded genres\n",
    "moviesGe = moviesG.copy()\n",
    "encodedG = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's']\n",
    "master = []\n",
    "for i in range(0,len(moviesGe)):\n",
    "    genre = []\n",
    "    for column in moviesGe.columns[4:]: \n",
    "        if (moviesGe.iloc[i][column] == 1):\n",
    "            genre.append(encodedG[moviesGe.columns.get_loc(column)-5])    \n",
    "            #print(genre)\n",
    "    master.append(genre)\n",
    "moviesGe['encoded_genre'] = master\n",
    "moviesGe['encoded_genre'] = moviesGe['encoded_genre'].astype('str')\n",
    "moviesGe = moviesGe.drop(moviesGe.columns[list(range(4,23))], axis=1) \n",
    "#moviesGe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies profile with '|' separated named genres\n",
    "moviesGn = moviesG.copy()\n",
    "named = []\n",
    "for i in range(0,len(moviesGn)):\n",
    "    genre = \"\"\n",
    "    for column in moviesGn.columns[5:]: \n",
    "        if (moviesGn.iloc[i][column] == 1):\n",
    "            genre = genre + column + '|'\n",
    "    genre = genre[:-1]\n",
    "    named.append(genre)\n",
    "moviesGn['genre_names'] = named\n",
    "moviesGn['genre_names'] = moviesGn['genre_names'].astype('str')\n",
    "moviesGn = moviesGn.drop(moviesGn.columns[list(range(4,23))], axis=1) \n",
    "#moviesGn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user-movie profile\n",
    "umCols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "um = pd.read_csv('ml-100k/u.data', sep='\\t', names=umCols)\n",
    "#um.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End loading all files - u.user, u.item, u.data into workable formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin creating workable DFs and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitting multi-genre movies into multiple 'same' movies with single genre\n",
    "new = ([(row['movie_id'], row['movie_title'], row['genre_names'].split('|'))              \n",
    "                    for _, row in moviesGn.iterrows()])#.reset_index()\n",
    "movCol = ['movie_id', 'movie_title', 'genre']\n",
    "newdf = pd.DataFrame(columns=movCol)\n",
    "i = 0\n",
    "for num1 in range(0,len(new)-1):\n",
    "    for num2 in range(0,len(new[num1][2])):\n",
    "        newdf.loc[i, 'movie_id'] = new[num1][0]\n",
    "        newdf.loc[i, 'movie_title'] = new[num1][1]\n",
    "        newdf.loc[i, 'genre'] = new[num1][2][num2]\n",
    "        i = i + 1\n",
    "newdf.to_csv('./FINAL/data/movie_genre.txt', columns= ['movie_title', 'genre'] ,sep='\\t',index=False,header=False,float_format='%.0f')\n",
    "#newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming movie - genre DF\n",
    "newdff = newdf.copy()\n",
    "newdff = newdff.drop('movie_id', axis=1)\n",
    "#newdff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming user_id - movie_id - rating - timestamp - movie_title.... DF\n",
    "newer = um.merge(moviesGn, left_on='movie_id', right_on='movie_id', how='inner')\n",
    "#newer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming user_id - movie_id - rating - timestamp - movie_title - age - gender .... DF\n",
    "rumerged = um.merge(users, left_on='user_id', right_on='user_id', how='inner')\n",
    "#rumerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming movie_title - ratings DF\n",
    "mrdf = newer.copy()\n",
    "mrdf = mrdf.drop(mrdf.columns[0:2], axis=1)\n",
    "mrdf = mrdf.drop(mrdf.columns[1:2], axis=1)\n",
    "mrdf = mrdf.drop(mrdf.columns[2:], axis=1)\n",
    "#mrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating movie: [all the ratings of that movie] file\n",
    "mr_map = {}\n",
    "#iterate over all movies\n",
    "for keyval in mrdf['movie_title']:\n",
    "    rat = []\n",
    "    #iterate over all movies rated by a user\n",
    "    if keyval in mr_map.keys():\n",
    "        mr_map[keyval].append(mrdf.loc[mrdf['movie_title'] == keyval, 'rating'].iloc[len(mr_map[keyval])])\n",
    "    else:\n",
    "        rat.append(mrdf.loc[mrdf['movie_title'] == keyval, 'rating'].iloc[0])\n",
    "        mr_map[keyval] = rat\n",
    "#mr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create movie - avg. rating dictionary\n",
    "avgDict = {}\n",
    "for k,v in mr_map.items():\n",
    "    # v is the list of grades for student k\n",
    "    avgDict[k] = sum(v)/ float(len(v))\n",
    "#avgDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the above dictionary to a DF\n",
    "avgDictdf = pd.DataFrame(columns=['movie_title', 'rating'])\n",
    "index = 0\n",
    "for k,v in avgDict.items():\n",
    "    index = index + 1\n",
    "    avgDictdf.loc[index, 'movie_title'] = k\n",
    "    avgDictdf.loc[index, 'rating'] = v\n",
    "#avgDictdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgDictdf.to_csv('./FINAL/data/movie_avg_rating.txt', columns= ['movie_title', 'rating'] ,sep='\\t',index=False,header=False,float_format='%.0f',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change timestamp to comprehendible DD-MM-YYYY form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newer = newer[newer['movie_title'] != 'unknown']\n",
    "newer = newer[newer['release_date'] != 'empty']\n",
    "newer.to_csv('./FINAL/data/jlt/Fullnewer.txt', sep='\\t',index=False,header=False,float_format='%.0f')\n",
    "newer.to_csv('./FINAL/data/jlt/newer.txt', columns= ['user_id', 'movie_title'] ,sep='\\t',index=False,header=False,float_format='%.0f')\n",
    "ncols = ['user_id', 'movie_id', 'rating', 'timestamp', 'movie_title','release_date', 'imdb_url', 'genre_names']\n",
    "newer = pd.read_csv('./FINAL/data/jlt/Fullnewer.txt', sep='\\t', names=ncols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin performing Content Based Recommendation (CBR)\n",
    "\n",
    "Since we want to build personalised recommendation, we compute similarity between movies based on certain metrics. Then, we can safely deduce/predict the movies that the user will like based on movie previously liked by the user. This is done using the similarity metric which is based on the attributes/content of the movies. Hence, it's called Content Based Recommendation (CBR). We can build the CBR model based on either all or a subset of a movie's attributes.\n",
    "\n",
    "Suppose, we build a CBR model with the movie name as one such attribute. For example, a movie 'Love Actually' and 'Love Story' would both fall into 'Romance' genre. Hence, based on the movie name, we can cluster similar named movies. However, this is NOT the best approach since it might also be misleading. For example, a movie 'Gone With The Wind' (Romance) might have nothing to do with 'Wind Chill' (Horror). We see this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DF with movie names without year\n",
    "cbr = moviesGn.copy()\n",
    "cbr['movie_title'] = cbr['movie_title'].map(lambda x: str(x)[:-7])\n",
    "#cbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using tf–idf or TFIDF (term frequency–inverse document frequency) approach of text mining to identify repetition of words in the movie names to recommend other movies having similar names to the given movie. Its value is proportional to the number of times a word appears in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using term frequency-inverse document frequency approach to for movie_name weighting\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "#returns T x D i.e. term document matrix\n",
    "tfidf_matrix = tf.fit_transform(moviesG['movie_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cosine Similarity: to compute similarity between two movies. Mathematically, it is cosine(x,y)= x.(y⊺) / (||x||.||y||) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this pairwise cosine similarity matrix for all the movies, we define a function that returns the topmost similar movies based on the cosine similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function gives us similar movies to a given movie based on text mining on movie_names\n",
    "indices = pd.Series(cbr.index, index=cbr['movie_title'])\n",
    "def get_similar(title):\n",
    "    print(\"The genre of the given movie is:\", cbr.loc[cbr['movie_title']==title,'genre_names'].iloc[0])\n",
    "    idx = indices[title]\n",
    "    sim_score = list(enumerate(cosine_sim[idx]))\n",
    "    sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)\n",
    "    sim_score = sim_score[1:11]#top10\n",
    "    movie_indices = [i[0] for i in sim_score]\n",
    "    for num in movie_indices:\n",
    "        print(cbr['movie_title'].iloc[num],\": \",cbr['genre_names'].iloc[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a DF of indices of each movie with movie name as index\n",
    "indices = pd.Series(cbr.index, index=cbr['movie_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genre of the given movie is: animation|children|comedy\n",
      "Pyromaniac's Love Story, A :  comedy|romance\n",
      "Now and Then :  drama\n",
      "Show, The :  documentary\n",
      "To Have, or Not :  drama\n",
      "Story of Xinghua, The :  drama\n",
      "Philadelphia Story, The :  comedy|romance\n",
      "NeverEnding Story III, The :  children|fantasy\n",
      "FairyTale: A True Story :  children|drama|fantasy\n",
      "Entertaining Angels: The Dorothy Day Story :  drama\n",
      "Police Story 4: Project S (Chao ji ji hua) :  action\n"
     ]
    }
   ],
   "source": [
    "#predicting similar movies using CBR approach\n",
    "get_similar('Toy Story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genre of the given movie is: comedy\n",
      "Love Is All There Is :  comedy|drama\n",
      "Penny Serenade :  drama|romance\n",
      "She's the One :  comedy|romance\n",
      "Two Much :  comedy|romance\n",
      "Before and After :  drama|mystery\n",
      "A Chef in Love :  comedy\n",
      "Pompatus of Love, The :  comedy|drama\n",
      "Hotel de Love :  comedy|romance\n",
      "Everyone Says I Love You :  comedy|musical|romance\n",
      "In Love and War :  romance|war\n"
     ]
    }
   ],
   "source": [
    "#predicting similar movies using CBR approach\n",
    "get_similar('Love Serenade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End performing Content Based Recommendation (CBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin performing Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the predictions are not so accurate since some genres differ by a lot. Hence, such a text mining approach would have been more useful, if we were given more details about the movies such as movie synopsis, cast, crew etc. This model doesn't give user-specific recommendations. Hence, to overcome this limitation arising due to limited descriptive data available in the MovieLens dataset, we compute user1's preference based on another similar user2's preference on the movies that the latter has reviewed but the former hasn't. This approach is called Collaborative Filtering (CF). We use Surprise library to implement CF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing a file containing user_id - movie_id - rating - timestamp\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(um[['user_id', 'movie_id', 'rating']], reader)\n",
    "#dividing the data into k-folds, here k=10\n",
    "kf = KFold(n_splits=10)\n",
    "#using SVD: matrix factorisation approach \n",
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9374\n",
      "RMSE: 0.9383\n",
      "RMSE: 0.9320\n",
      "RMSE: 0.9308\n",
      "RMSE: 0.9286\n",
      "RMSE: 0.9200\n",
      "RMSE: 0.9343\n",
      "RMSE: 0.9365\n",
      "RMSE: 0.9173\n",
      "RMSE: 0.9256\n"
     ]
    }
   ],
   "source": [
    "#performing training, testing and calculating RMSE\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=10, iid=336, r_ui=3, est=3.1033947237688957, details={'was_impossible': False})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting the rating for user_id = 10 and movie_id = 336\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "algo.predict(10, 336, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get a predicted rating of 3.10 for user_id = 10 and movie_id = 336. This CF approach of movie recommendation is independent of the content of the movie (like genres etc.) since the basis of its prediction is solely on how other similar users have rated the movie. However, this is also not the best way to approach the problem. So, we move on to actually making use of the attributes of each review for a movie by a user by performing feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End performing Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin feature engineering\n",
    "\n",
    "Here, we add a new feature: timeSinceRelease = timestamp - release_date. Other features like day of the week, month of the year can also be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting time columns into datetime format\n",
    "newer['release_date'] = pd.to_datetime(newer['release_date'], format='%d-%b-%Y')\n",
    "for i in range(0,len(newer)):\n",
    "    newer.loc[i,'timestamp'] = datetime.fromtimestamp(newer.loc[i,'timestamp'])\n",
    "newer['timestamp'] = pd.to_datetime(newer['timestamp'], format='%d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to get the timespan between two datetime objects\n",
    "def days_between(d1, d2):\n",
    "    return abs((d1 - d2).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating timeSinceRelease column\n",
    "ctr = 0\n",
    "for i in newer['movie_title']:\n",
    "    newer.loc[ctr,'timeSinceRelease'] = days_between(newer.loc[ctr,'timestamp'],newer.loc[ctr,'release_date'])\n",
    "    ctr = ctr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating dict out of this dataframe for all, min and max review release span of a movie \n",
    "all = {}\n",
    "cnt = 0\n",
    "for mov in newer['movie_title']:\n",
    "    nummin = 0\n",
    "    nummax = 0\n",
    "    m = []\n",
    "    if mov in all.keys():\n",
    "        all[mov].append(newer.loc[newer['movie_title'] == mov, 'timeSinceRelease'].iloc[len(all[mov])])\n",
    "    else:\n",
    "        cnt = cnt + 1\n",
    "        m.append(newer.loc[newer['movie_title'] == mov, 'timeSinceRelease'].iloc[0])\n",
    "        all[mov] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary for timespan for each review of a movie\n",
    "mindict = {}\n",
    "maxdict = {}\n",
    "spandict = {}\n",
    "\n",
    "for ur in all.keys():\n",
    "    #minh = []\n",
    "    #maxh = []\n",
    "    if ur in mindict.keys():\n",
    "        continue\n",
    "    #using min-heap and max-heap\n",
    "    else:\n",
    "        if all[ur] != []:\n",
    "            minhh = all[ur]\n",
    "            heapq.heapify(minhh)\n",
    "            mindict[ur] = heapq.heappop(minhh)\n",
    "    if ur in maxdict.keys():\n",
    "        continue\n",
    "    else:\n",
    "        if all[ur] != []:\n",
    "            maxhh = all[ur]\n",
    "            heapq._heapify_max(maxhh)\n",
    "            maxdict[ur] = heapq._heappop_max(maxhh)\n",
    "    if ur in spandict.keys():\n",
    "        continue\n",
    "    else:\n",
    "        if all[ur] != []:\n",
    "            spandict[ur] = [maxdict[ur] - mindict[ur]]\n",
    "#mindict\n",
    "#maxdict\n",
    "#spandict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the above dictionary to a DF\n",
    "timespan = pd.DataFrame.from_dict(spandict)\n",
    "timespan = timespan.T\n",
    "timespan.reset_index(level=0, inplace=True)\n",
    "timespan.columns = ['movie_title', 'timespan']\n",
    "#timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the DF to file\n",
    "timespan.to_csv('./FINAL/data/features/movie_timespan.txt',sep='\\t',index=False,header=False,float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating users: [all the movies the user has rated] file\n",
    "um_dict = {}\n",
    "cnt = 0\n",
    "for user in newer['user_id']:\n",
    "    mov=[]\n",
    "    if user in um_dict.keys():\n",
    "        um_dict[user].append(newer.loc[newer['user_id'] == user, 'movie_title'].iloc[len(um_dict[user])])\n",
    "    else:\n",
    "        cnt = cnt + 1\n",
    "        mov.append(newer.loc[newer['user_id'] == user, 'movie_title'].iloc[0])\n",
    "        um_dict[user] = mov\n",
    "#um_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the above dict into DF\n",
    "um_dictdf = pd.DataFrame(columns=['user_id', 'movie_title'])\n",
    "index = 0\n",
    "for k,v in um_dict.items():\n",
    "    index = index + 1\n",
    "    um_dictdf.loc[index, 'user_id'] = k\n",
    "    um_dictdf.loc[index, 'movie_title'] = v\n",
    "#um_dictdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the above DF to file\n",
    "um_dictdf.to_csv('./FINAL/data/user_movies.txt', columns= ['user_id', 'movie_title'] ,sep='\\t',index=False,header=False,float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating users: [all the rating values by the user] file\n",
    "ur_dict = {}\n",
    "hold=0\n",
    "for user in um['user_id']:\n",
    "    mov=[]\n",
    "    if user in ur_dict.keys():\n",
    "        ur_dict[user].append(um.loc[um['user_id'] == user, 'rating'].iloc[len(ur_dict[user])])\n",
    "    else:\n",
    "        hold = hold+1\n",
    "        mov.append(um.loc[um['user_id'] == user, 'rating'].iloc[0])\n",
    "        ur_dict[user] = mov\n",
    "#ur_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "um1 = []\n",
    "um1 = list(um_dict.keys())\n",
    "um2 = []\n",
    "um2 = list(um_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin performing graph computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of nodes in the graph:  943\n"
     ]
    }
   ],
   "source": [
    "#calculating edge weights for weighted directed user movie graph\n",
    "weighted_directed_user_movie_graph = open(\"./FINAL/data/wd_um_graph.txt\", 'w')\n",
    "p = 0\n",
    "counter = 0\n",
    "print(\"The total number of nodes in the graph: \",len(um_dict))\n",
    "while p < len(um1):\n",
    "    u1 = um1[p]\n",
    "    u1m = um_dict[u1]\n",
    "    #cos we don't to check for the same user with him/herself!\n",
    "    q = p + 1 \n",
    "    while q < len(um2):\n",
    "        u2 = um2[q]\n",
    "        u2m = um_dict[u2]\n",
    "        overlap_movies = set(u1m) & set(u2m)\n",
    "        #edge weight tells us what proportion of movies do two users have rated in common\n",
    "        if len(overlap_movies) > 0:\n",
    "            u1Ratio = decimal.Decimal(len(overlap_movies)) \\\n",
    "                / decimal.Decimal(len(u1m))\n",
    "            u1Ratio = format(u1Ratio, '.3f')\n",
    "            u2Ratio = decimal.Decimal(len(overlap_movies)) \\\n",
    "                / decimal.Decimal(len(u2m))\n",
    "            u2Ratio = format(u2Ratio, '.3f')\n",
    "            weighted_directed_user_movie_graph.write(u1.astype(str) + '\\t' + u2.astype(str) + '\\t' + str(u1Ratio) + '\\n')\n",
    "            weighted_directed_user_movie_graph.write(u2.astype(str) + '\\t' + u1.astype(str) + '\\t' + str(u2Ratio) + '\\n')\n",
    "            counter = counter + 1\n",
    "        q = q + 1\n",
    "    p = p + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call R script for weighted directed user network: WD_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating movie: [all the users that rated this movie] file\n",
    "#iterate over all users\n",
    "movie_map = {}\n",
    "for keyval in um_dict.keys():\n",
    "    #iterate over all movies rated by a user\n",
    "    for movie in um_dict[keyval]:\n",
    "        if (movie in movie_map):\n",
    "            user_list = movie_map[movie]\n",
    "            if keyval not in user_list:\n",
    "                user_list.append(keyval)         \n",
    "                movie_map[movie] = user_list\n",
    "        else:\n",
    "            movie_map[movie] = [keyval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov1 = []\n",
    "mov1 = list(movie_map.keys())\n",
    "mov2 = []\n",
    "mov2 = list(movie_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of nodes in the graph: 1663\n"
     ]
    }
   ],
   "source": [
    "#calculating edge weights for weighted undirected movie user graph\n",
    "weighted_undirected_movie_graph = open(\"./FINAL/data/wu_movie_graph.txt\", 'w')\n",
    "p = 0\n",
    "counter = 0\n",
    "print(\"The total number of nodes in the graph:\",len(mov1))\n",
    "while p < len(mov1):\n",
    "    mov1_id = mov1[p]\n",
    "    mov1_users = movie_map[mov1_id]\n",
    "    q = p + 1\n",
    "    while q < len(mov2):\n",
    "        mov2_id = mov2[q]\n",
    "        mov2_users = movie_map[mov2_id]\n",
    "        overlap_actors = set(mov1_users) & set(mov2_users)\n",
    "        if(len(overlap_actors) > 0):\n",
    "            #calculating jaccard index as edge weight\n",
    "            jaccard_index = decimal.Decimal(len(overlap_actors) * 100)/(decimal.Decimal(len(mov1_users) + len(mov2_users) - len(overlap_actors)))\n",
    "            weighted_undirected_movie_graph.write(str(mov1_id) + \"\\t\" + str(mov2_id) + \"\\t\" + str(jaccard_index) + \"\\n\")\n",
    "            counter = counter + 1\n",
    "        q = q + 1\n",
    "    p = p + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End performing graph computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call R script for weighted undirected movie network: WU_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user_id - pagerank dictionary\n",
    "pg_reader = open(\"./FINAL/data/top943userpg.txt\", \"r\")\n",
    "page_rank = {}\n",
    "for row in pg_reader.readlines():\n",
    "    content = row.strip().split('\\t')\n",
    "    content[0] = content[0].strip('\"\"')\n",
    "    page_rank[content[0]] = float(ast.literal_eval(content[1]))\n",
    "\n",
    "#getting list of all user_id numbers\n",
    "u_id = []\n",
    "for key in um_dict.keys():\n",
    "    usr = key\n",
    "    u_id.append(usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building unordered set with unique user_id\n",
    "page_rank = {int(k):float(v) for k, v in page_rank.items()}\n",
    "u_id = np.ravel(np.ravel(np.array(u_id))) #flattened array\n",
    "u_id = set(u_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building movie - pageranks of users that rated that movie dictionary\n",
    "output = {}\n",
    "for key in um_dict.keys():\n",
    "    usr = key\n",
    "    mvs = um_dict[usr]\n",
    "    pgval = page_rank[usr]\n",
    "    for any in mvs:\n",
    "        if any not in output:\n",
    "            output[any] = []\n",
    "        output[any].append(pgval)\n",
    "#len(page_rank)\n",
    "#len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of pg values are: 99991\n",
      "The min number of pg values are: 1\n",
      "The max number of pg values are: 583\n"
     ]
    }
   ],
   "source": [
    "#checking number of pagerank values in movie - pageranks of users dictionary\n",
    "nu = 0\n",
    "for i in output.keys():\n",
    "    nu = nu + len(output[i])\n",
    "print(\"The total number of pg values are:\", nu)\n",
    "nuumin = 583\n",
    "nuumax = 0\n",
    "#length of pg values for each user- find max\n",
    "for i in output.keys():\n",
    "    if len(output[i]) < nuumin:\n",
    "        nuumin = len(output[i])\n",
    "    if len(output[i]) > nuumax:\n",
    "        nuumax = len(output[i])\n",
    "#might not be equal to number of users since one user could have rated more than one movie\n",
    "print(\"The min number of pg values are:\", nuumin)\n",
    "print(\"The max number of pg values are:\", nuumax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating output file with top 5 pageranks of each movie\n",
    "ouputFile = open('./FINAL/data/features/movie_pageranks_top5.txt',\"w\")\n",
    "for movie in output.keys():\n",
    "    pagerankVal = output[movie]\n",
    "    pagerankVal.sort(reverse=True)\n",
    "    strPgRnk =\"\"\n",
    "    for val in range(0,5):#specifies number of (top) pagerank values to be taken (since sorted in decreasing order)\n",
    "        if(val< len(pagerankVal)):\n",
    "            y = pagerankVal[val]\n",
    "            strPgRnk = strPgRnk+str(y)+\"\\t\"\n",
    "        else:\n",
    "            strPgRnk = strPgRnk+\"0\"+\"\\t\"\n",
    "    final = movie+\"\\t\"+strPgRnk+\"\\n\"\n",
    "    ouputFile.write(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to file\n",
    "ratings = pd.read_csv('./FINAL/data/movie_avg_rating_processed.txt', sep='\\t', names=['movie_title','rating'],encoding='latin-1')\n",
    "ratings = ratings.drop(ratings.index[0])\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating movie - avg. rating dictionary\n",
    "mrate = {}\n",
    "for val in range(1,len(ratings)):\n",
    "    mrate[ratings.loc[val,'movie_title']] = ratings.loc[val,'rating']\n",
    "#mrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the above dict to DF\n",
    "mrate_df = pd.DataFrame(list(mrate.items()), columns=['movie_title', 'rating'])\n",
    "#mrate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting movies by rating in descending order\n",
    "d_sorted_by_value = OrderedDict(sorted(mrate.items(), key=lambda x: x[1], reverse=True))\n",
    "#d_sorted_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting top 100 movies in terms of avg. rating\n",
    "top100 = dict(islice(d_sorted_by_value.items(), 100))\n",
    "top100_movies = top100.keys()\n",
    "#top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user - avg. rating by the user for all its movies dictionary\n",
    "for key in mrate.keys():\n",
    "    mrate[key] = float(mrate[key])\n",
    "\n",
    "user_rating = {}\n",
    "i = 0\n",
    "for u in um_dict.keys():\n",
    "    #print i\n",
    "    v = []\n",
    "    for m in um_dict[u]:\n",
    "        if m in mrate.keys():\n",
    "            v.append(mrate[m])\n",
    "    user_rating[u] = sum(v)/len(v)\n",
    "    i += 1\n",
    "#user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating movie - avg. rating by all the users that have reviewed that movie dictionary\n",
    "movie_to_actor_rating = {}\n",
    "i = 0\n",
    "for m in mrate.keys():\n",
    "    v = []\n",
    "    for u in movie_map[m]:\n",
    "        v.append(float(user_rating[u]))#a[1:-1]]))\n",
    "    movie_to_actor_rating[m] = sorted(v,reverse=True)#[:5]\n",
    "    i += 1\n",
    "#movie_to_actor_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatig a movie - timespan dictionary \n",
    "md_reader = open('./FINAL/data/features/movie_timespan.txt', 'r')\n",
    "\n",
    "movies_timespan = {}\n",
    "movies = []\n",
    "tsp = []\n",
    "i = 1\n",
    "for md in md_reader:\n",
    "    content = md.strip().split(\"\\t\")\n",
    "    for x in content:\n",
    "        movies.append(content[0])\n",
    "        tsp.append(content[1])\n",
    "    i += 1\n",
    "movies_tsp = dict(zip(movies, tsp))\n",
    "#movies_tsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the above dict to DF\n",
    "tsp_df = pd.DataFrame(list(movies_tsp.items()), columns=['movie_title', 'timespan'])\n",
    "#tsp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DF with top 5 pageranks for users that rated that movie\n",
    "df = pd.read_csv('./FINAL/data/movie_pageranks.txt', sep=\"\\t\", encoding='latin-1',header = None, names = ['movie_title','pg1','pg2','pg3','pg4','pg5','pg6','rating'])#,'Timespan'])\n",
    "df['rating'] = 0\n",
    "fdf = tsp_df.merge(df, left_on='movie_title', right_on='movie_title', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting timespan to integer type\n",
    "fdf['timespan'] = fdf['timespan'].astype('int64')\n",
    "fdf = fdf.drop(fdf.columns[7], axis=1) #dropping pg6 since empty\n",
    "#fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling up rating column of fdf\n",
    "tsps = []\n",
    "movies = []\n",
    "nrows = fdf.shape[0]\n",
    "for i in range(0,nrows):\n",
    "    movie = df.iloc[i,0]\n",
    "    if movie in mrate:\n",
    "        #print(\"yo\")\n",
    "        fdf.iloc[i,7] = mrate[movie]\n",
    "#fdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping NA values in fdf\n",
    "fdf = fdf.dropna() \n",
    "#fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model is trained on- age, gender, occupation, genres. Since gender and occupation are categorical features, they are one-hot encoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing base feature DF\n",
    "mrgr = um.merge(moviesG, left_on='movie_id', right_on='movie_id', how='inner')\n",
    "mergedd = mrgr.merge(users, left_on='user_id', right_on='user_id', how='inner')\n",
    "rqdc = ['user_id','movie_title','age','occupation','gender']+genres#+['rating']\n",
    "bline = mergedd[rqdc]\n",
    "#keeping non-empty values\n",
    "bline = bline[bline['gender'] != 'empty']\n",
    "bline = bline[bline['occupation'] != 'empty']\n",
    "#using one-hot encoding for categorical features like gender(M/F), occupation\n",
    "bline['occupation'] = bline['occupation'].astype('category')\n",
    "bline['gender'] = bline['gender'].astype('category')\n",
    "one_hot_occ = bline.occupation.str.get_dummies()\n",
    "bline = bline.drop('occupation',axis=1)\n",
    "bline = bline.join(one_hot_occ,how='inner')\n",
    "one_hot_g = bline.gender.str.get_dummies()\n",
    "bline = bline.drop('gender',axis=1)\n",
    "bline = bline.join(one_hot_g,how='inner')\n",
    "bbline = bline.merge(avgDictdf, left_on='movie_title', right_on='movie_title', how='inner')\n",
    "bbline = bbline.drop('user_id',axis=1)\n",
    "#bline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features that are added are: \n",
    "1. timespan between movie release and review date\n",
    "2. pageranks of the top 5 users that have rated that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing feature DF including engineered features\n",
    "fdf = fdf.drop('rating',axis=1)\n",
    "fdff = fdf.merge(bbline, left_on='movie_title', right_on='movie_title', how='inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into test and train data\n",
    "X = fdff.iloc[:,1:50]#:,1:50]#0:len(fdf),1:7]\n",
    "y = fdff.iloc[:,50:]#:,50:]#0:len(fdf),7:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for Little Buddha (1993)\n",
      "[ 3.99145299]\n",
      "prediction for Little Big League (1994)\n",
      "[ 3.5532394]\n",
      "prediction for Metro (1997)\n",
      "[ 3.74587459]\n"
     ]
    }
   ],
   "source": [
    "############################## Baseline Modelling (without engineered features) #################################\n",
    "xb_train = bbline.iloc[0:1000,1:44]\n",
    "yb_train = bbline.iloc[0:1000,44:]\n",
    "rcl = tree.DecisionTreeRegressor()\n",
    "rclf = rcl.fit(xb_train, yb_train)\n",
    "for i in range(1, len(bbline)):\n",
    "    movie = bbline.iloc[i, 0]\n",
    "    if(movie == 'Little Buddha (1993)'):\n",
    "        mov1_feature = bbline.iloc[i,1:44]\n",
    "    if(movie == 'Little Big League (1994)'):\n",
    "        mov2_feature = bbline.iloc[i,1:44]\n",
    "    if (movie == 'Metro (1997)'):\n",
    "        mov3_feature = bbline.iloc[i, 1:44]\n",
    "#predicting rating for some movies\n",
    "print(\"prediction for Little Buddha (1993)\")\n",
    "print(rclf.predict([mov1_feature]))\n",
    "print(\"prediction for Little Big League (1994)\")\n",
    "print(rclf.predict([mov2_feature]))\n",
    "print(\"prediction for Metro (1997)\")\n",
    "print(rclf.predict([mov3_feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.346443585594\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting accuracy scores\n",
    "print(\"score: \",(model.score(X_train, y_train)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for Little Buddha (1993)\n",
      "[[ 3.43663628]]\n",
      "prediction for Little Big League (1994)\n",
      "[[ 2.5772907]]\n",
      "prediction for Metro (1997)\n",
      "[[ 3.16664091]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################## Linear Regression #################################\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(X_train, y_train)\n",
    "for i in range(1, len(fdff)):\n",
    "    movie = fdff.iloc[i, 0]\n",
    "    if(movie == 'Little Buddha (1993)'):\n",
    "        mov1_feature = fdff.iloc[i,1:50]\n",
    "    if(movie == 'Little Big League (1994)'):\n",
    "        mov2_feature = fdff.iloc[i,1:50]\n",
    "    if (movie == 'Metro (1997)'):\n",
    "        mov3_feature = fdff.iloc[i, 1:50]\n",
    "\n",
    "#predicting rating for same set of movies\n",
    "print(\"prediction for Little Buddha (1993)\")\n",
    "print(regr.predict([mov1_feature]))\n",
    "print(\"prediction for Little Big League (1994)\")\n",
    "print(regr.predict([mov2_feature]))\n",
    "print(\"prediction for Metro (1997)\")\n",
    "print(regr.predict([mov3_feature]))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Linear Regression Model')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEWCAYAAABfdFHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ed5b656d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting true values v/s predictions of linear regression (top 100 values)\n",
    "predictions = regr.predict(X_test)\n",
    "plt.scatter(y_test[0:100], predictions[0:100])\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Linear Regression Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores: \n",
      " [ 0.34028047  0.37086327  0.31849793  0.32726282  0.34128561  0.33365316\n",
      "  0.36486928  0.34915655  0.3538425   0.35127401]\n",
      "score without cv: 0.3464435855937428\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performing 10-fold CV and getting accuracy scores\n",
    "lr_scores = cross_val_score(model, X_train, y_train, cv = 10)\n",
    "print(\"cross validation scores: \\n\",lr_scores)\n",
    "print(\"score without cv: {}\".format(model.score(X_train, y_train)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for Little Buddha (1993)\n",
      "[ 3.31818182]\n",
      "prediction for Little Big League (1994)\n",
      "[ 2.875]\n",
      "prediction for Metro (1997)\n",
      "[ 2.91666667]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################## Decision Tree #################################\n",
    "dtr = tree.DecisionTreeRegressor()\n",
    "dtm = dtr.fit(X_train, y_train)\n",
    "for i in range(1, len(fdff)):\n",
    "    movie = fdff.iloc[i, 0]\n",
    "    if(movie == 'Little Buddha (1993)'):\n",
    "        mov1_feature = fdff.iloc[i,1:50]\n",
    "    if(movie == 'Little Big League (1994)'):\n",
    "        mov2_feature = fdff.iloc[i,1:50]\n",
    "    if (movie == 'Metro (1997)'):\n",
    "        mov3_feature = fdff.iloc[i, 1:50]\n",
    "\n",
    "#predicting rating for same set of movies\n",
    "print(\"prediction for Little Buddha (1993)\")\n",
    "print(dtr.predict([mov1_feature]))\n",
    "print(\"prediction for Little Big League (1994)\")\n",
    "print(dtr.predict([mov2_feature]))\n",
    "print(\"prediction for Metro (1997)\")\n",
    "print(dtr.predict([mov3_feature]))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores: \n",
      " [ 0.95904142  0.95993954  0.96006499  0.95271631  0.96080743  0.95839962\n",
      "  0.95652143  0.95568772  0.9603449   0.95416337]\n",
      "score without cv: 0.9886007071924332\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performing 10-fold CV and getting accuracy scores\n",
    "dt_scores = cross_val_score(dtm, X_train, y_train, cv = 10)\n",
    "print(\"cross validation scores: \\n\",dt_scores)\n",
    "print(\"score without cv: {}\".format(dtm.score(X_train, y_train)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that the Decision Tree model performs better than the Linear Regression model. It has higher cross validation scores and gives accurate prediction for the ratings of the three movies taken above (with their actual average ratings being very close to the predictions by the DT model). In comparison to the baseline model, both LR and DT have done a good job in predicting the movie ratings and that feature engineering has been useful in bumping up the accuracy from 36.4% to about 98% after cross-validation using the DT model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
